# Return of the Jedi

## üìù Problem Description

Given a set of $N$ planets, and the costs to establish a direct, two-way information channel between any pair of them, the goal is to construct a network of channels that connects all planets. A network is considered connected if information can be transmitted between any two planets, either directly or indirectly through other planets. The total cost of a network is the sum of the costs of all channels it contains.

A specific method for building a network is proposed: starting with a designated planet (Tatooine, with index $i$), the network is grown one planet at a time. In each step, we identify the planet not yet in the network that can be connected to any planet already in the network with the cheapest possible channel. This planet and its cheapest connecting channel are then added. Ties are broken by preferring planets with a smaller index (higher importance).

Your task is to find the minimum possible cost for a connected network that is **different** from the one produced by the specific method described. A network is different if its set of channels is not identical. For each test case, you will be given the number of planets $N$, the index of the starting planet $i$, and the costs for all possible channels. You must output the cost of this second-best network.

## üí° Hints

<details>
<summary>Hint #1</summary>
The problem asks for a "warp network" that connects all planets at a certain cost. What is the minimum number of channels required to connect $N$ planets? A network that achieves this minimum is a fundamental structure in computer science. Also, consider the properties of a network that connects all planets with the minimum possible total cost.
</details>
<details>
<summary>Hint #2</summary>
Princess Leia's algorithm for building the network is a greedy one. It starts with one planet and iteratively adds the cheapest connection to a new planet. This process is identical to a famous algorithm used for finding a **Minimum Spanning Tree (MST)**, namely **Prim's Algorithm**. The problem, therefore, asks for the cost of the cheapest spanning tree that is not the one generated by Prim's algorithm. This is known as the **Second-Best Minimum Spanning Tree**.
</details>
<details>
<summary>Hint #3</summary>
A common way to find the Second-Best MST is to start with the First MST. Since the second-best tree must differ by at least one channel (edge), we can try to generate candidate trees by making minimal changes to the first one. For each channel that is part of the First MST, what happens if you are forbidden from using it? You would have to find the best possible network without that specific channel. The Second-Best MST will be the best among these alternatives.
</details>

## ‚ú® Solutions

<details>
<summary>First Solution (Test Set 1)</summary>

### From Planets to Graphs
First, we can model this problem using graph theory. The planets can be represented as **vertices** and the transmission channels as **edges** connecting these vertices. Since a cost is defined for a channel between any two planets, we have a **complete, weighted, undirected graph**.

A "warp network" that connects all planets is a **spanning tree** of this graph. The problem asks for the cheapest such network, which corresponds to a **Minimum Spanning Tree (MST)**. Princess Leia's method is a textbook description of **Prim's algorithm**, which is a standard algorithm to find an MST.

The core task is to find the minimum cost of a warp network that is *different* from Leia's. This is equivalent to finding the **Second-Best Minimum Spanning Tree**.

### A Brute-Force Approach
For a small number of planets ($N \le 100$), a straightforward brute-force strategy is feasible. The logic is as follows:

1.  **Find the First MST:** Compute the MST of the graph using a standard algorithm like Kruskal's or Prim's. Let the set of edges in this MST be $T$.
2.  **Generate Candidate Trees:** The Second-Best MST must differ from the first one by at least one edge. We can generate candidates for the second-best tree by systematically modifying the first MST. We iterate through each edge $e$ in $T$.
3.  **Compute Costs:** For each edge $e \in T$, we temporarily remove it from the graph and find the MST of the remaining graph. If the graph becomes disconnected, no spanning tree can be formed. Otherwise, we calculate the cost of this new MST.
4.  **Find the Minimum:** The cost of the Second-Best MST is the minimum cost among all the valid MSTs computed in the previous step.

### Complexity
This approach involves running an MST algorithm (like Kruskal's, which is $O(E \log V)$) for each of the $N-1$ edges in the initial MST. In a complete graph, the number of edges $E$ is $O(N^2)$. This results in a total complexity of roughly $O(N \cdot E \log V) = O(N \cdot N^2 \log N) = O(N^3 \log N)$, which is acceptable for $N \le 100$.

The following C++ code implements this logic using the Boost Graph Library's `kruskal_minimum_spanning_tree` function.

```cpp
#include <iostream>
#include <vector>
#include <limits>

#include <boost/graph/adjacency_list.hpp>
#include <boost/graph/kruskal_min_spanning_tree.hpp>

typedef boost::adjacency_list<boost::vecS, boost::vecS, boost::undirectedS,
  boost::no_property, boost::property<boost::edge_weight_t, int> >      weighted_graph;
typedef boost::property_map<weighted_graph, boost::edge_weight_t>::type weight_map;
typedef boost::graph_traits<weighted_graph>::edge_descriptor            edge_desc;
typedef boost::graph_traits<weighted_graph>::vertex_descriptor          vertex_desc;

void solve() {
  // ===== READ INPUT =====
  int n, source; std::cin >> n >> source;
  source--; // Adjust from 1-based to 0-based indexing
  
  std::vector<std::vector<int>> distances(n);
  
  weighted_graph G(n);
  weighted_graph G_copy(n);
  for(int i = 1; i < n; ++i) {
    for(int j = 1; j < n - (i - 1); ++j) {
      int k; std::cin >> k;
      boost::add_edge(i - 1, i - 1 + j, k, G);
      boost::add_edge(i - 1, i - 1 + j, k, G_copy);
      distances[i-1].push_back(k);
    }
  }
  
  // ===== FIND MST =====
  std::vector<edge_desc> mst;
  boost::kruskal_minimum_spanning_tree(G, std::back_inserter(mst));

  // ===== FIND MINIMUM WEIGHT OF ALTERNATIVE MST =====
  long min_mst_weight = std::numeric_limits<long>::max();
for (const edge_desc &e : mst) {
    int u = boost::source(e, G);
    int v = boost::target(e, G);

    // Remove edge
    boost::remove_edge(u, v, G_copy);

    // Calculate new MST
    std::vector<edge_desc> new_mst;
    boost::kruskal_minimum_spanning_tree(G_copy, std::back_inserter(new_mst));

    if (new_mst.size() < n - 1) {
        // Graph is disconnected
        boost::add_edge(u, v, distances[u][v - u - 1], G_copy);
        continue;
    }

    // Calculate new MST weight
    long mst_weight = 0;
    for (const edge_desc &new_e : new_mst) {
        int new_u = boost::source(new_e, G_copy);
        int new_v = boost::target(new_e, G_copy);

        int min_index = std::min(new_u, new_v);
        int max_index = std::max(new_u, new_v);
        mst_weight += distances[min_index][max_index - min_index - 1];
    }

    min_mst_weight = std::min(min_mst_weight, mst_weight);

    // Add edge back
    boost::add_edge(u, v, distances[u][v - u - 1], G_copy);
}

  // ===== OUTPUT =====
  std::cout << min_mst_weight << std::endl;
}

int main() {
  std::ios_base::sync_with_stdio(false);
  
  int n_tests; std::cin >> n_tests;
  while(n_tests--) { solve(); }
}
```
</details>
<details>
<summary>Final Solution</summary>

### Identifying the Bottleneck
The previous solution is correct, but its $O(N^3 \log N)$ complexity makes it too slow for larger values of $N$. The primary performance bottleneck is repeatedly calling a full MST algorithm. Each call to Kruskal's algorithm, for instance, involves sorting all $O(N^2)$ edges, an operation we perform $N-1$ times.

### Optimization: Sort Once, Reuse Often
A significant optimization is to avoid re-sorting the edges. We can sort all edges in the graph by weight *once* at the beginning. Then, we can manually implement Kruskal's algorithm, which uses the sorted list and a Union-Find data structure, to build our candidate MSTs.

### Refined Algorithm
1.  **Edge Preparation:** Create a single list containing all $O(N^2)$ edges of the graph.
2.  **Initial Sort:** Sort this list of edges by weight in non-decreasing order. This is an $O(E \log E)$ operation, where $E$ is the number of edges.
3.  **Find the First MST:** Find the primary MST by iterating through the sorted edge list and using a Union-Find data structure to add edges that connect disjoint sets of vertices. Store the edges that form this MST.
4.  **Find the Second-Best MST:** To find the second-best MST, we iterate through each edge $e_{MST}$ from the primary MST we just found.
    - For each $e_{MST}$, we want to find the cost of the best spanning tree that does not include it.
    - To do this, we re-initialize a Union-Find data structure. Then, we iterate through our single, pre-sorted list of all edges. When building the new tree, we add edges just as in Kruskal's algorithm but explicitly *skip* the edge $e_{MST}$.
    - The total weight of the resulting tree is a candidate for the second-best MST cost.
5.  **Final Answer:** The minimum cost found across all choices of a skipped edge $e_{MST}$ is the final answer.

### Complexity Analysis
- **Sorting Edges:** With $E = O(N^2)$ edges, sorting takes $O(E \log E) = O(N^2 \log N)$.
- **Finding First MST:** Kruskal's with a Union-Find data structure takes $O(E \alpha(N)) = O(N^2 \alpha(N))$ after sorting, where $\alpha(N)$ is the very slow-growing inverse Ackermann function.
- **Main Loop:** We loop $N-1$ times (once for each edge in the MST). Inside this loop, we iterate through all $E$ edges and perform Union-Find operations. This part of the algorithm takes $O(N \cdot E \cdot \alpha(N)) = O(N^3 \alpha(N))$.

The overall complexity is dominated by the main loop, resulting in an $O(N^3 \alpha(N))$ runtime. This is an improvement over the first solution and is sufficient to pass more test cases, though it might still be too slow for the largest constraints without further optimization.

```cpp
#include <iostream>
#include <vector>
#include <limits>

#include <boost/pending/disjoint_sets.hpp>

typedef std::tuple<int, int, int> Edge;

const int MAX_INT = std::numeric_limits<int>::max();

void solve() {
  // ===== READ INPUT =====
  int n, source; std::cin >> n >> source;

  std::vector<Edge> edges;
  for(int j = 1; j <= n - 1; ++j) {
    for(int k = 1; k <= n - j; ++k) {
      int d; std::cin >> d;
      // Adjust for 0-based indexing
      edges.emplace_back(j - 1, j + k - 1, d);
    }
  }
  int n_edges = edges.size();
  
  // ===== FIND MST =====
  // Sort list of edges based on their distance
  std::sort(edges.begin(), edges.end(), [](const Edge &a, const Edge &b) {
    return std::get<2>(a) < std::get<2>(b);  
  });
  
  // Find MST using Kruskals Algorithm
  std::vector<Edge*> mst_edges; mst_edges.reserve(n-1);
  boost::disjoint_sets_with_storage<> mst_uf(n);
  int n_components = n;
  for(int i = 0; i < n_edges; ++i) {
    int c1 = mst_uf.find_set(std::get<0>(edges[i]));
    int c2 = mst_uf.find_set(std::get<1>(edges[i]));
    
    if(c1 != c2 ) {
      mst_uf.link(c1, c2);
      mst_edges.push_back(&edges[i]);
      if (--n_components == 1) break;
    }
  }
  
  // Find 2nd best MST by skipping one edge of the MST (otherwise Kruskal)
  int min_mst_weight = MAX_INT;
  for(const Edge *skip_edge : mst_edges) {
    int mst_weight = 0;
    
    boost::disjoint_sets_with_storage<> uf(n);
    int n_components = n;
    for(int i = 0; i < n_edges; ++i) {
      if(&edges[i] == skip_edge) { continue; }
      
      int c1 = uf.find_set(std::get<0>(edges[i]));
      int c2 = uf.find_set(std::get<1>(edges[i]));
      
      if(c1 != c2 ) {
        uf.link(c1, c2);
        mst_weight += std::get<2>(edges[i]);
        if (--n_components == 1) break;
      }
    }
    
    min_mst_weight = std::min(min_mst_weight, mst_weight);
  }
  
  // ===== OUTPUT =====
  std::cout << min_mst_weight << std::endl;
}

int main() {
  std::ios_base::sync_with_stdio(false);
  
  int n_tests; std::cin >> n_tests;
  while(n_tests--) { solve(); }
}
```
</details>

## ‚ö° Result

```plaintext

```